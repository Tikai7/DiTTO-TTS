{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from model.SpeechLP import SLP\n",
    "\n",
    "from utils.Config import Config\n",
    "from utils.MLS import MLSDataset\n",
    "from utils.Trainer import Trainer\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Settings:\n",
      "  Sample Rate: 24000 Hz\n",
      "  Min Audio Duration: 10 seconds\n",
      "  Max Audio Duration: 20 seconds\n",
      "\n",
      "Text Settings:\n",
      "  Max Token : 64 tokens\n",
      "\n",
      "Model Settings:\n",
      "  Model Name: DiTTO-TTS\n",
      "  Embedding Dim: 1472\n",
      "  Num Layers: 1\n",
      "  Attention Heads: 1\n",
      "\n",
      "Training Settings:\n",
      "  Batch Size: 8\n",
      "  Learning Rate: 0.0001\n",
      "  Betas: [0.9, 0.999]\n",
      "  Epochs: 10\n",
      "  Nb samples: 10000\n",
      "  Device: cuda\n",
      "\n",
      "Data Settings:\n",
      "  Train path: C:/Cours-Sorbonne/M2/UE_DEEP/AMAL/Projet/data/mls_french_opus/mls_french_opus/train\n",
      "  Test path: C:/Cours-Sorbonne/M2/UE_DEEP/AMAL/Projet/data/mls_french_opus/mls_french_opus/test\n",
      "  Dev path: C:/Cours-Sorbonne/M2/UE_DEEP/AMAL/Projet/data/mls_french_opus/mls_french_opus/dev\n"
     ]
    }
   ],
   "source": [
    "Config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing transcripts and saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258213it [01:18, 3293.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing transcripts and saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2416it [00:00, 2421.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing transcripts and saving results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2426it [00:00, 2451.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set = MLSDataset(\n",
    "    data_dir=Config.TRAIN_PATH,\n",
    "    max_text_token_length=Config.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=Config.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "val_set = MLSDataset(\n",
    "    data_dir=Config.DEV_PATH,\n",
    "    max_text_token_length=Config.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=Config.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "test_set = MLSDataset(\n",
    "    data_dir=Config.TEST_PATH,\n",
    "    max_text_token_length=Config.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=Config.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=Config.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=Config.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=Config.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i, batch in enumerate(tqdm(train_loader)):\n",
    "    try:\n",
    "        # Process the batch as normal\n",
    "        text = {key: val.to(Config.DEVICE) for key, val in batch[\"text\"].items()}\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"[ERROR] UnicodeDecodeError in batch {i}: {e}\")\n",
    "        break\n",
    "    if i == 10:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SLP(Config.MAX_AUDIO_DURATION, Config.NHEAD ,Config.NUM_LAYERS).to(Config.DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.set_model(model, name=\"SLP\")\\\n",
    "    .set_criterion(criterion)\\\n",
    "    .set_optimizer(optimizer)\\\n",
    "    .fit(\n",
    "        train_data=train_loader, validation_data=val_loader, \n",
    "        epochs=Config.EPOCHS, learning_rate=Config.LEARNING_RATE, checkpoint_interval=1        \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
