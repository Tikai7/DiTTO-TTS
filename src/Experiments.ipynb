{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.SpeechLP import SLP\n",
    "from model.NeuralAudioCodec import NAC\n",
    "\n",
    "from utils.Config import ConfigSLP, ConfigNAC\n",
    "from utils.MLS import MLSDataset\n",
    "from utils.Trainer import Trainer\n",
    "from utils.Processing import Processing\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigSLP.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.TRAIN_PATH+\"/\"+\"audio\", ConfigSLP.TRAIN_PATH+\"/\"+\"audio_clean\",)\n",
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.TEST_PATH+\"/\"+\"audio\", ConfigSLP.TEST_PATH+\"/\"+\"audio_clean\",)\n",
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.DEV_PATH+\"/\"+\"audio\", ConfigSLP.DEV_PATH+\"/\"+\"audio_clean\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MLSDataset(\n",
    "    data_dir=ConfigSLP.TRAIN_PATH,\n",
    "    max_text_token_length=ConfigSLP.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigSLP.SAMPLE_RATE,\n",
    "    nb_samples = ConfigSLP.NB_SAMPLES\n",
    ")\n",
    "\n",
    "val_set = MLSDataset(\n",
    "    data_dir=ConfigSLP.DEV_PATH,\n",
    "    max_text_token_length=ConfigSLP.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigSLP.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "\n",
    "test_set = MLSDataset(\n",
    "    data_dir=ConfigSLP.TEST_PATH,\n",
    "    max_text_token_length=ConfigSLP.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigSLP.SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=ConfigSLP.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=ConfigSLP.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=ConfigSLP.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_slp = SLP(ConfigSLP.NB_CLASSES, ConfigSLP.NHEAD ,ConfigSLP.NUM_LAYERS)\n",
    "model_slp = model_slp.to(ConfigSLP.DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW\n",
    "\n",
    "trainer = Trainer()\n",
    "trainer.set_model(model_slp, name=ConfigSLP.MODEL_NAME)\\\n",
    "    .set_criterion(criterion)\\\n",
    "    .set_optimizer(optimizer)\\\n",
    "    .fit(\n",
    "        train_data=train_loader, validation_data=val_loader, \n",
    "        epochs=ConfigSLP.EPOCHS, learning_rate=ConfigSLP.LEARNING_RATE, checkpoint_interval=1        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MLSDataset(\n",
    "    data_dir=ConfigNAC.TRAIN_PATH,\n",
    "    max_text_token_length=ConfigNAC.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigNAC.SAMPLE_RATE,\n",
    "    nb_samples = ConfigNAC.NB_SAMPLES,\n",
    "    tokenizer_model=\"gpt2\"\n",
    ")\n",
    "\n",
    "val_set = MLSDataset(\n",
    "    data_dir=ConfigNAC.DEV_PATH,\n",
    "    max_text_token_length=ConfigNAC.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigNAC.SAMPLE_RATE,\n",
    "    tokenizer_model=\"gpt2\"\n",
    ")\n",
    "\n",
    "test_set = MLSDataset(\n",
    "    data_dir=ConfigNAC.TEST_PATH,\n",
    "    max_text_token_length=ConfigNAC.MAX_TOKEN_LENGTH,\n",
    "    sampling_rate=ConfigNAC.SAMPLE_RATE,\n",
    "    tokenizer_model=\"gpt2\"\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=ConfigNAC.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "val_loader = DataLoader(val_set, batch_size=ConfigNAC.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=ConfigNAC.BATCH_SIZE, shuffle=True, collate_fn=MLSDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nac = NAC(ConfigNAC.LAMBDA_FACTOR)\n",
    "model_nac = model_nac.to(ConfigNAC.DEVICE)\n",
    "optimizer = torch.optim.AdamW\n",
    "\n",
    "\n",
    "def train(self, train_loader):\n",
    "    losses = 0\n",
    "    self.model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch[\"text\"][\"input_ids\"] = batch[\"text\"][\"input_ids\"].to(self.device)\n",
    "        batch[\"text\"][\"attention_mask\"] = batch[\"text\"][\"attention_mask\"].to(self.device)\n",
    "\n",
    "        text = batch[\"text\"]\n",
    "        audio = batch[\"audio\"].to(self.device)\n",
    "        padding_mask_audio = batch[\"padding_mask_audio\"].to(self.device)\n",
    "\n",
    "        output = self.model(text, audio, padding_mask_audio)\n",
    "        loss = output[\"total_loss\"]\n",
    "\n",
    "        losses += loss.item()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    return losses / len(train_loader), {\"lm_loss\" : output[\"lm_loss\"], \"reconstruction_loss\": output[\"reconstruction_loss\"]}\n",
    "\n",
    "\n",
    "def validation(self, validation_loader):\n",
    "    losses = 0\n",
    "    self.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_loader):\n",
    "            batch[\"text\"][\"input_ids\"] = batch[\"text\"][\"input_ids\"].to(self.device)\n",
    "            batch[\"text\"][\"attention_mask\"] = batch[\"text\"][\"attention_mask\"].to(self.device)\n",
    "            \n",
    "            text = batch[\"text\"]\n",
    "            audio = batch[\"audio\"].to(self.device)\n",
    "            padding_mask_audio = batch[\"padding_mask_audio\"].to(self.device)\n",
    "\n",
    "            output = self.model(text, audio, padding_mask_audio)\n",
    "            loss = output[\"total_loss\"]\n",
    "            \n",
    "            losses += loss.item()\n",
    "\n",
    "    return losses / len(validation_loader), {\"lm_loss\" : output[\"lm_loss\"], \"reconstruction_loss\": output[\"reconstruction_loss\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "trainer.set_model(model_nac, name=ConfigNAC.MODEL_NAME)\\\n",
    "    .set_criterion(torch.nn.MSELoss)\\\n",
    "    .set_optimizer(optimizer)\\\n",
    "    .set_custom_functions(train_func=train, validation_func=validation)\\\n",
    "    .fit(\n",
    "        train_data=train_loader, validation_data=val_loader, \n",
    "        epochs=ConfigNAC.EPOCHS, learning_rate=ConfigNAC.LEARNING_RATE, checkpoint_interval=1        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
