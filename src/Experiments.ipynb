{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from model.SpeechGenerator import SpeechGenerator\n",
    "from utils.Config import ConfigSLP, ConfigNAC, ConfigDiTTO\n",
    "from utils.MLS import MLSDataset\n",
    "from utils.Trainer import Trainer\n",
    "from utils.Processing import Processing\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Base Settings: #############\n",
      "\n",
      "Audio Settings:\n",
      "  Sample Rate: 24000 Hz\n",
      "  Min Audio Duration: 10 seconds\n",
      "  Max Audio Duration: 20 seconds\n",
      "\n",
      "Training Settings:\n",
      "  Betas: [0.9, 0.999]\n",
      "  Device: cuda\n",
      "\n",
      "Data Settings:\n",
      "  Train Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/train\n",
      "  Test Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/test\n",
      "  Dev Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/dev\n",
      "\n",
      "############# SLP Settings: #############\n",
      "\n",
      "Model Settings:\n",
      "  Model Name: SLP\n",
      "  Embedding Dimension: 1472\n",
      "  Number of Layers: 1\n",
      "  Number of Attention Heads: 1\n",
      "  Number of Classes: 11\n",
      "  Number of Samples: 10000\n",
      "  Batch Size: 8\n",
      "  Learning Rate: 0.0001\n",
      "  Epochs: 20\n",
      "  Token length for ByT5: 128\n",
      "############# Base Settings: #############\n",
      "\n",
      "Audio Settings:\n",
      "  Sample Rate: 24000 Hz\n",
      "  Min Audio Duration: 10 seconds\n",
      "  Max Audio Duration: 20 seconds\n",
      "\n",
      "Training Settings:\n",
      "  Betas: [0.9, 0.999]\n",
      "  Device: cuda\n",
      "\n",
      "Data Settings:\n",
      "  Train Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/train\n",
      "  Test Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/test\n",
      "  Dev Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/dev\n",
      "\n",
      "############# NAC Settings: #############\n",
      "\n",
      "Model Settings:\n",
      "  Model Name: NAC\n",
      "  Lambda Factor: 0.1\n",
      "  Number of Samples: 10000\n",
      "  Batch Size: 4\n",
      "  Learning Rate: 0.0001\n",
      "  Epochs: 20\n",
      "  Token length for GPT2: 1024\n",
      "############# Base Settings: #############\n",
      "\n",
      "Audio Settings:\n",
      "  Sample Rate: 24000 Hz\n",
      "  Min Audio Duration: 10 seconds\n",
      "  Max Audio Duration: 20 seconds\n",
      "\n",
      "Training Settings:\n",
      "  Betas: [0.9, 0.999]\n",
      "  Device: cuda\n",
      "\n",
      "Data Settings:\n",
      "  Train Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/train\n",
      "  Test Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/test\n",
      "  Dev Path: /tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/data/mls_french_opus/dev\n",
      "\n",
      "############# DiTTO Settings: #############\n",
      "\n",
      "Model Architecture Settings:\n",
      "  Model Name: DiTTO\n",
      "  Hidden Dimension: 768\n",
      "  Number of Layers: 5\n",
      "  Number of Attention Heads: 1\n",
      "  Time Embedding Dimension: 256\n",
      "  Text Embedding Dimension: 768\n",
      "\n",
      "Diffusion Process Settings:\n",
      "  Diffusion Steps: 1000\n",
      "\n",
      "Training Settings:\n",
      "  Epochs: 20\n",
      "  Learning Rate: 0.0001\n",
      "  Batch Size: 8\n",
      "\n",
      "Data Settings:\n",
      "  Number of Samples: 10000\n",
      "  Max Token Length: 1024\n"
     ]
    }
   ],
   "source": [
    "ConfigSLP.display()\n",
    "ConfigNAC.display()\n",
    "ConfigDiTTO.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.TRAIN_PATH+\"/\"+\"audio\", ConfigSLP.TRAIN_PATH+\"/\"+\"audio_clean\",)\n",
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.TEST_PATH+\"/\"+\"audio\", ConfigSLP.TEST_PATH+\"/\"+\"audio_clean\",)\n",
    "# Processing.remove_metadata_from_audio_folder(ConfigSLP.DEV_PATH+\"/\"+\"audio\", ConfigSLP.DEV_PATH+\"/\"+\"audio_clean\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Generation with DiTTO-TTs and Vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading NAC model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/.venv/lib/python3.9/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/src/model/DiTTO.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nac_info = torch.load(nac_model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] NAC Loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/src/model/SpeechGenerator.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ditto_info = torch.load(ditto_model_path, map_location=self.device)\n",
      "/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/.venv/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from nvidia/bigvgan_v2_24khz_100band_256x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/src/bigvgan_v2_24khz_100band_256x/bigvgan.py:481: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_dict = torch.load(model_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "speech_generator = SpeechGenerator(\n",
    "    nac_model_path=\"/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/src/params/NAC_epoch_20.pth\",\n",
    "    ditto_model_path=\"/tempory/M2-DAC/UE_DEEP/AMAL/DiTTO-TTS/src/params/DiTTO_epoch_20.pth\",\n",
    "    lambda_factor=ConfigNAC.LAMBDA_FACTOR,\n",
    "    sample_rate=ConfigNAC.SAMPLE_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_generator.generate_speech_from_audio_tensor(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
